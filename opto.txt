-- Hoogle documentation, generated by Haddock
-- See Hoogle, http://www.haskell.org/hoogle/


-- | General-purpose performant numeric optimization library
--   
--   Please see the README on Github at
--   <a>https://github.com/mstksg/opto#readme</a>
@package opto
@version 0.1.0.0


-- | Abstract over different types for mutable references of values.
module Numeric.Opto.Ref

-- | Abstraction over types of mutable references for values. A
--   <tt><a>Ref</a> m a v</tt> means that a <tt>v</tt> is a mutable
--   reference to an <tt>a</tt>, and we may update<i>write</i>modify
--   <tt>v</tt> in context <tt>m</tt>.
--   
--   This allows us to reat mutable vectors and in-place mutable numbers or
--   records in the same way.
class Monad m => Ref m a v | v -> a

-- | Initialize a mutable reference with a given value
thawRef :: Ref m a v => a -> m v

-- | Read an immutable value back from a mutable reference
freezeRef :: Ref m a v => v -> m a

-- | Copy an immutable value into a mutable reference
copyRef :: Ref m a v => v -> a -> m ()

-- | Apply a pure function on an immutable value onto a value stored in a
--   mutable reference.
modifyRef :: Ref m a v => v -> (a -> a) -> m ()

-- | <a>modifyRef</a>, but forces the result before storing it back in the
--   reference.
modifyRef' :: Ref m a v => v -> (a -> a) -> m ()

-- | Apply a pure function on an immutable value onto a value stored in a
--   mutable reference, returning a result value from that function.
updateRef :: Ref m a v => v -> (a -> (a, b)) -> m b

-- | <a>updateRef</a>, but forces the updated value before storing it back
--   in the reference.
updateRef' :: Ref m a v => v -> (a -> (a, b)) -> m b
instance (Control.Monad.Primitive.PrimMonad m, Control.Monad.Primitive.PrimState m Data.Type.Equality.~ s) => Numeric.Opto.Ref.Ref m a (Data.Primitive.MutVar.MutVar s a)
instance (Control.Monad.Primitive.PrimMonad m, Control.Monad.Primitive.PrimState m Data.Type.Equality.~ s) => Numeric.Opto.Ref.Ref m (Data.Vector.Vector a) (Data.Vector.Mutable.MVector s a)
instance (Control.Monad.Primitive.PrimMonad m, Data.Vector.Generic.Base.Mutable v Data.Type.Equality.~ mv, Control.Monad.Primitive.PrimState m Data.Type.Equality.~ s, Data.Vector.Generic.Base.Vector v a) => Numeric.Opto.Ref.Ref m (Data.Vector.Generic.Sized.Internal.Vector v n a) (Data.Vector.Generic.Mutable.Sized.Internal.MVector mv n s a)
instance GHC.Base.Monad m => Numeric.Opto.Ref.Ref m () ()
instance (GHC.Base.Monad m, Numeric.Opto.Ref.Ref m a u, Numeric.Opto.Ref.Ref m b v) => Numeric.Opto.Ref.Ref m (a, b) (u, v)
instance (GHC.Base.Monad m, Numeric.Opto.Ref.Ref m a u, Numeric.Opto.Ref.Ref m b v, Numeric.Opto.Ref.Ref m c w) => Numeric.Opto.Ref.Ref m (a, b, c) (u, v, w)
instance (GHC.Base.Monad m, Numeric.Opto.Ref.Ref m a u, Numeric.Opto.Ref.Ref m b v, Numeric.Opto.Ref.Ref m c w, Numeric.Opto.Ref.Ref m d j) => Numeric.Opto.Ref.Ref m (a, b, c, d) (u, v, w, j)


-- | Conduits that are useful for sampling and running optimizers.
module Numeric.Opto.Run.Conduit

-- | Outputs a shuffled version of the input stream. Keeps entire input
--   stream in memory.
--   
--   NOTE: Pulls the entire input stream into memory first before
--   outputting anything.
shuffling :: PrimMonad m => Gen (PrimState m) -> ConduitT a a m ()

-- | Takes the first N items out of the input stream, shuffles them
--   in-memory, and outputs the shuffled result.
--   
--   Leaves the rest of the items in the stream.
--   
--   Use <a>forever</a> to repeat multiple times until the stream is
--   exhausted.
shufflingN :: PrimMonad m => Int -> Gen (PrimState m) -> ConduitT a a m ()

-- | Process an entire stream, and keep N random and shuffled items from
--   that stream. Is O(N) memory.
sinkSampleReservoir :: forall m v a o. (PrimMonad m, Vector v a) => Int -> Gen (PrimState m) -> ConduitT a o m (v a)

-- | Process an entire stream, and yield N random items from that stream.
--   Is O(N) memory.
--   
--   NOTE: Exhausts the entire input stream first before outputting
--   anything, but never keeps the entire original stream in memory.
samplingN :: PrimMonad m => Int -> Gen (PrimState m) -> ConduitT a a m ()

-- | Drops and lets items through randomly with a given probability.
skipSampling :: PrimMonad m => Double -> Gen (PrimState m) -> ConduitT a a m ()

module Numeric.Opto.Update
class Additive a
(.+.) :: Additive a => a -> a -> a
addZero :: Additive a => a
(.+.) :: (Additive a, Num a) => a -> a -> a
addZero :: (Additive a, Num a) => a
infixl 6 .+.
sumAdditive :: (Additive a, Foldable t) => t a -> a
gAdd :: (ADTRecord a, Constraints a Additive) => a -> a -> a
gAddZero :: (ADTRecord a, Constraints a Additive) => a
class (Num c, Additive a) => Scaling c a | a -> c
(.*) :: Scaling c a => c -> a -> a
scaleOne :: Scaling c a => c
(.*) :: (Scaling c a, ADTRecord a, Constraints a (Scaling c)) => c -> a -> a
infixl 7 .*
gScale :: forall c a. (ADTRecord a, Constraints a (Scaling c)) => c -> a -> a
class Scaling c a => Metric c a

-- | Sum of component-wise product
(<.>) :: Metric c a => a -> a -> c

-- | Maximum absolute component
norm_inf :: Metric c a => a -> c

-- | Number of non-zero components
norm_0 :: Metric c a => a -> c

-- | Sum of absolute components
norm_1 :: Metric c a => a -> c

-- | Square root of sum of squared components
norm_2 :: Metric c a => a -> c

-- | Sum of squared components
quadrance :: Metric c a => a -> c

-- | Sum of component-wise product
(<.>) :: (Metric c a, ADT a, Constraints a (Metric c)) => a -> a -> c

-- | Maximum absolute component
norm_inf :: (Metric c a, ADT a, Constraints a (Metric c), Ord c) => a -> c

-- | Number of non-zero components
norm_0 :: (Metric c a, ADT a, Constraints a (Metric c)) => a -> c

-- | Sum of absolute components
norm_1 :: (Metric c a, ADT a, Constraints a (Metric c)) => a -> c

-- | Square root of sum of squared components
norm_2 :: (Metric c a, Floating c) => a -> c

-- | Sum of squared components
quadrance :: (Metric c a, ADT a, Constraints a (Metric c)) => a -> c
infixl 7 <.>
gNorm_inf :: forall c a. (ADT a, Constraints a (Metric c), Ord c) => a -> c
gNorm_0 :: forall c a. (ADT a, Constraints a (Metric c), Num c) => a -> c
gNorm_1 :: forall c a. (ADT a, Constraints a (Metric c), Num c) => a -> c
gNorm_2 :: forall c a. (ADT a, Constraints a (Metric c), Floating c) => a -> c
gQuadrance :: forall c a. (ADT a, Constraints a (Metric c), Num c) => a -> c
class (Ref m a v, Additive a) => AdditiveInPlace m v a
(.+.=) :: AdditiveInPlace m v a => v -> a -> m ()
infix 4 .+.=
sumAdditiveInPlace :: (AdditiveInPlace m v a, Foldable t) => v -> t a -> m ()
class (AdditiveInPlace m v a, Scaling c a) => ScalingInPlace m v c a
(.*=) :: ScalingInPlace m v c a => v -> c -> m ()
(.*+=) :: ScalingInPlace m v c a => v -> (c, a) -> m ()
infix 4 .*=
infix 4 .*+=
instance Numeric.Opto.Ref.Ref m GHC.Types.Double v => Numeric.Opto.Update.ScalingInPlace m v GHC.Types.Double GHC.Types.Double
instance (Control.Monad.Primitive.PrimMonad m, Control.Monad.Primitive.PrimState m Data.Type.Equality.~ s, GHC.Num.Num a, mv Data.Type.Equality.~ Data.Vector.Generic.Base.Mutable v, Data.Vector.Generic.Base.Vector v a, GHC.TypeNats.KnownNat n) => Numeric.Opto.Update.ScalingInPlace m (Data.Vector.Generic.Mutable.Sized.Internal.MVector mv n s a) a (Data.Vector.Generic.Sized.Internal.Vector v n a)
instance (GHC.TypeNats.KnownNat n, Numeric.Opto.Ref.Ref m (Internal.Static.R n) v) => Numeric.Opto.Update.ScalingInPlace m v GHC.Types.Double (Internal.Static.R n)
instance (GHC.TypeNats.KnownNat n, GHC.TypeNats.KnownNat k, Numeric.Opto.Ref.Ref m (Internal.Static.L n k) v) => Numeric.Opto.Update.ScalingInPlace m v GHC.Types.Double (Internal.Static.L n k)
instance (Numeric.Opto.Ref.Ref m (a, b) v, Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b) => Numeric.Opto.Update.ScalingInPlace m v c (a, b)
instance (Numeric.Opto.Ref.Ref m (a, b, d) v, Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b, Numeric.Opto.Update.Scaling c d) => Numeric.Opto.Update.ScalingInPlace m v c (a, b, d)
instance (Numeric.Opto.Ref.Ref m (a, b, d, e) v, Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b, Numeric.Opto.Update.Scaling c d, Numeric.Opto.Update.Scaling c e) => Numeric.Opto.Update.ScalingInPlace m v c (a, b, d, e)
instance (Numeric.Opto.Ref.Ref m (a, b, d, e, f) v, Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b, Numeric.Opto.Update.Scaling c d, Numeric.Opto.Update.Scaling c e, Numeric.Opto.Update.Scaling c f) => Numeric.Opto.Update.ScalingInPlace m v c (a, b, d, e, f)
instance Numeric.Opto.Ref.Ref m GHC.Types.Double v => Numeric.Opto.Update.AdditiveInPlace m v GHC.Types.Double
instance (Control.Monad.Primitive.PrimMonad m, Control.Monad.Primitive.PrimState m Data.Type.Equality.~ s, GHC.Num.Num a, mv Data.Type.Equality.~ Data.Vector.Generic.Base.Mutable v, Data.Vector.Generic.Base.Vector v a, GHC.TypeNats.KnownNat n) => Numeric.Opto.Update.AdditiveInPlace m (Data.Vector.Generic.Mutable.Sized.Internal.MVector mv n s a) (Data.Vector.Generic.Sized.Internal.Vector v n a)
instance (GHC.TypeNats.KnownNat n, Numeric.Opto.Ref.Ref m (Internal.Static.R n) v) => Numeric.Opto.Update.AdditiveInPlace m v (Internal.Static.R n)
instance (GHC.TypeNats.KnownNat n, GHC.TypeNats.KnownNat k, Numeric.Opto.Ref.Ref m (Internal.Static.L n k) v) => Numeric.Opto.Update.AdditiveInPlace m v (Internal.Static.L n k)
instance (Numeric.Opto.Ref.Ref m (a, b) v, Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b) => Numeric.Opto.Update.AdditiveInPlace m v (a, b)
instance (Numeric.Opto.Ref.Ref m (a, b, c) v, Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b, Numeric.Opto.Update.Additive c) => Numeric.Opto.Update.AdditiveInPlace m v (a, b, c)
instance (Numeric.Opto.Ref.Ref m (a, b, c, d) v, Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b, Numeric.Opto.Update.Additive c, Numeric.Opto.Update.Additive d) => Numeric.Opto.Update.AdditiveInPlace m v (a, b, c, d)
instance (Numeric.Opto.Ref.Ref m (a, b, c, d, e) v, Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b, Numeric.Opto.Update.Additive c, Numeric.Opto.Update.Additive d, Numeric.Opto.Update.Additive e) => Numeric.Opto.Update.AdditiveInPlace m v (a, b, c, d, e)
instance Numeric.Opto.Update.Metric GHC.Types.Double GHC.Types.Double
instance (GHC.Float.Floating a, GHC.Classes.Ord a, Data.Vector.Generic.Base.Vector v a, GHC.TypeNats.KnownNat n) => Numeric.Opto.Update.Metric a (Data.Vector.Generic.Sized.Internal.Vector v n a)
instance GHC.TypeNats.KnownNat n => Numeric.Opto.Update.Metric GHC.Types.Double (Internal.Static.R n)
instance (GHC.TypeNats.KnownNat n, GHC.TypeNats.KnownNat m) => Numeric.Opto.Update.Metric GHC.Types.Double (Internal.Static.L n m)
instance (Numeric.Opto.Update.Metric c a, Numeric.Opto.Update.Metric c b, GHC.Classes.Ord c, GHC.Float.Floating c) => Numeric.Opto.Update.Metric c (a, b)
instance (Numeric.Opto.Update.Metric c a, Numeric.Opto.Update.Metric c b, Numeric.Opto.Update.Metric c d, GHC.Classes.Ord c, GHC.Float.Floating c) => Numeric.Opto.Update.Metric c (a, b, d)
instance (Numeric.Opto.Update.Metric c a, Numeric.Opto.Update.Metric c b, Numeric.Opto.Update.Metric c d, Numeric.Opto.Update.Metric c e, GHC.Classes.Ord c, GHC.Float.Floating c) => Numeric.Opto.Update.Metric c (a, b, d, e)
instance (Numeric.Opto.Update.Metric c a, Numeric.Opto.Update.Metric c b, Numeric.Opto.Update.Metric c d, Numeric.Opto.Update.Metric c e, Numeric.Opto.Update.Metric c f, GHC.Classes.Ord c, GHC.Float.Floating c) => Numeric.Opto.Update.Metric c (a, b, d, e, f)
instance Numeric.Opto.Update.Scaling GHC.Types.Double GHC.Types.Double
instance (GHC.Num.Num a, Data.Vector.Generic.Base.Vector v a, GHC.TypeNats.KnownNat n) => Numeric.Opto.Update.Scaling a (Data.Vector.Generic.Sized.Internal.Vector v n a)
instance GHC.TypeNats.KnownNat n => Numeric.Opto.Update.Scaling GHC.Types.Double (Internal.Static.R n)
instance (GHC.TypeNats.KnownNat n, GHC.TypeNats.KnownNat m) => Numeric.Opto.Update.Scaling GHC.Types.Double (Internal.Static.L n m)
instance (Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b) => Numeric.Opto.Update.Scaling c (a, b)
instance (Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b, Numeric.Opto.Update.Scaling c d) => Numeric.Opto.Update.Scaling c (a, b, d)
instance (Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b, Numeric.Opto.Update.Scaling c d, Numeric.Opto.Update.Scaling c e) => Numeric.Opto.Update.Scaling c (a, b, d, e)
instance (Numeric.Opto.Update.Scaling c a, Numeric.Opto.Update.Scaling c b, Numeric.Opto.Update.Scaling c d, Numeric.Opto.Update.Scaling c e, Numeric.Opto.Update.Scaling c f) => Numeric.Opto.Update.Scaling c (a, b, d, e, f)
instance Numeric.Opto.Update.Additive GHC.Types.Double
instance (GHC.Num.Num a, Data.Vector.Generic.Base.Vector v a, GHC.TypeNats.KnownNat n) => Numeric.Opto.Update.Additive (Data.Vector.Generic.Sized.Internal.Vector v n a)
instance Numeric.Opto.Update.Additive (Internal.Static.R n)
instance (GHC.TypeNats.KnownNat n, GHC.TypeNats.KnownNat m) => Numeric.Opto.Update.Additive (Internal.Static.L n m)
instance (Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b) => Numeric.Opto.Update.Additive (a, b)
instance (Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b, Numeric.Opto.Update.Additive c) => Numeric.Opto.Update.Additive (a, b, c)
instance (Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b, Numeric.Opto.Update.Additive c, Numeric.Opto.Update.Additive d) => Numeric.Opto.Update.Additive (a, b, c, d)
instance (Numeric.Opto.Update.Additive a, Numeric.Opto.Update.Additive b, Numeric.Opto.Update.Additive c, Numeric.Opto.Update.Additive d, Numeric.Opto.Update.Additive e) => Numeric.Opto.Update.Additive (a, b, c, d, e)

module Numeric.Opto.Core
type Diff a = a
type Grad m r a = r -> a -> m (Diff a)
data Opto :: (Type -> Type) -> Type -> Type -> Type -> Type
[MkOpto] :: forall s u m v r a c. (ScalingInPlace m v c a, Ref m s u) => {oInit :: !s, oUpdate :: !u -> r -> a -> m (c, Diff a)} -> Opto m v r a
mapSample :: (r -> s) -> Opto m v s a -> Opto m v r a
fromCopying :: (PrimMonad m, ScalingInPlace m v c a) => s -> (r -> a -> s -> m (c, Diff a, s)) -> Opto m v r a
fromStateless :: ScalingInPlace m v c a => (r -> a -> m (c, Diff a)) -> Opto m v r a
pureGrad :: Applicative m => (r -> a -> Diff a) -> Grad m r a
nonSampling :: (a -> m (Diff a)) -> Grad m r a
pureNonSampling :: Applicative m => (a -> Diff a) -> Grad m r a


-- | Functions to <i>run</i> optimiziers.
module Numeric.Opto.Run

-- | Options for running an optimizer.
data RunOpts m a
RO :: (Diff a -> a -> m Bool) -> (a -> m ()) -> Maybe Int -> Int -> Maybe Int -> RunOpts m a

-- | Stop condition; will stop when <a>True</a> (default = never stop)
[roStopCond] :: RunOpts m a -> Diff a -> a -> m Bool

-- | Reporting function (default = no report)
[roReport] :: RunOpts m a -> a -> m ()

-- | Number of batches to run (Nothing = run forever) (default = Nothing).
[roLimit] :: RunOpts m a -> Maybe Int

-- | Size of batching updates (1 = no batching) (default = 1)
[roBatch] :: RunOpts m a -> Int

-- | batches per report (Nothing = never report) (default = Just 1).
[roFreq] :: RunOpts m a -> Maybe Int

-- | Map over the underlying monad of a <a>RunOpts</a>.
hoistRunOpts :: (forall x. m x -> n x) -> RunOpts m a -> RunOpts n a

-- | Options for running an optimizer in a concurrent setting.
data ParallelOpts m a
PO :: Maybe Int -> Int -> (NonEmpty a -> m a) -> Bool -> ParallelOpts m a

-- | Number of threads (Nothing = max capacity) (default = Nothing)
[poThreads] :: ParallelOpts m a -> Maybe Int

-- | How many batches thread will process before regrouping (default =
--   1000)
[poSplit] :: ParallelOpts m a -> Int

-- | How to recombine a pool of updated results into a single result
--   (default = <tt><a>pure</a> <a>.</a> <a>mean</a></tt>)
[poCombine] :: ParallelOpts m a -> NonEmpty a -> m a

-- | For conduit runners, whether or not conduit is in "pull-based" mode,
--   where optimization doesn't happen until requested downstream. This is
--   ignored if not running via conduit (default = True)
[poPull] :: ParallelOpts m a -> Bool

-- | Map over the underlying monad of a <a>ParallelOpts</a>.
hoistParallelOpts :: (forall x. m x -> n x) -> ParallelOpts m a -> ParallelOpts n a

-- | Run an optimizer on some input, given a monadic action to produce each
--   new sample. When the action produces <a>Nothing</a>, the running
--   immediately terminates even if the stop condition has not yet been
--   met.
opto :: Monad m => RunOpts m a -> m (Maybe r) -> a -> Opto m v r a -> m a

-- | A version of <a>opto</a> that also returns an updated optimizer state
--   that can be resumed.
opto' :: Monad m => RunOpts m a -> m (Maybe r) -> a -> Opto m v r a -> m (a, Opto m v r a)

-- | A version of <a>optoNonSampling</a> that also returns an updated
--   optimizer state that can be resumed.
optoNonSampling' :: Monad m => RunOpts m a -> a -> Opto m v () a -> m (a, Opto m v () a)

-- | Run a non-sampling optimizer on some input until the stop condition is
--   met.
optoNonSampling :: Monad m => RunOpts m a -> a -> Opto m v () a -> m a

-- | Given an optimizer and some initial value, produce a <a>ConduitT</a>
--   that takes in samples and outputs each successively optimized versions
--   of the value. This essentially is a convenient wrapper over
--   <a>opto</a>.
--   
--   To get the <i>final</i> optimized result after a stream has
--   terminated, compose this with a sink like <a>last</a>.
--   
--   <pre>
--   <a>optoConduit</a> ro x0 o .| <a>last</a>
--     :: ConduitT r o m (Maybe a)
--   
--   <a>optoConduit</a> ro x0 o .| <a>lastDef</a> x0
--     :: ConduitT r o m a
--   </pre>
optoConduit :: Monad m => RunOpts m a -> a -> Opto (ConduitT r a m) v r a -> ConduitT r a m ()

-- | A version of <a>optoConduit</a> that also returns an updated optimizer
--   state that can be resumed.
optoConduit' :: Monad m => RunOpts m a -> a -> Opto (ConduitT r a m) v r a -> ConduitT r a m (Opto (ConduitT r a m) v r a)

-- | Convenient wrapper over <a>opto</a> to allow consumption over a list
--   of samples.
optoFold :: Monad m => RunOpts m a -> a -> Opto (StateT [r] m) v r a -> [r] -> m (a, [r])

-- | A version of <a>optoFold'</a> that also returns an updated optimizer
--   state that can be resumed.
optoFold' :: Monad m => RunOpts m a -> a -> Opto (StateT [r] m) v r a -> [r] -> m (a, [r], Opto (StateT [r] m) v r a)

-- | Run an optimizer in parallel on multiple threads on some value, given
--   a (thread-safe) monadic action to produce each new sample.
--   
--   It does this by repeatedly:
--   
--   <ol>
--   <li>Splitting into multiple threads (based on <a>poThreads</a>)</li>
--   <li>Running <a>opto</a> (single-threaded optimiztion) on each thread,
--   independently, from the same initial value.</li>
--   <li>After <a>poSplit</a> items have been processed, all threads wait
--   on each other to stop. After each thread is done, each thread's
--   optimized value is then aggregated using <a>poCombine</a> (by default,
--   it takes the mean).</li>
--   <li>This new optimized combined value is then used to begin the cycle
--   again.</li>
--   </ol>
--   
--   When action produces <a>Nothing</a> for <i>all</i> threads, the
--   running immediately terminates on all threads and returns even if the
--   stop condition has not yet been met. If the stop condition is met, the
--   value given to the stop condition will be used as the final result,
--   ignoring all other thread pools.
optoPar :: forall m v r a. MonadUnliftIO m => RunOpts m a -> ParallelOpts m a -> m (Maybe r) -> a -> Opto m v r a -> m a

-- | A version of <a>optoPar</a> that performs a batch fetch for each
--   thread's entire sample pool <i>before</i> beginning parallel
--   optimization. This can be useful if the sampling is faster in batch
--   amounts.
optoParChunk :: forall m v r a. MonadUnliftIO m => RunOpts m a -> ParallelOpts m a -> (Int -> m [r]) -> a -> Opto (StateT [r] m) v r a -> m a

-- | Run a non-sampling optimizer in parallel on multiple threads on some
--   value until the stop condition is met.
--   
--   See <a>optoPar</a> for a detailed description of how parallel
--   optimization is implemented.
optoParNonSampling :: MonadUnliftIO m => RunOpts m a -> ParallelOpts m a -> a -> Opto m v () a -> m a

-- | Given an optimizer, some initial value, and a conduit <i>source</i>,
--   returns a conduit sorce that outputs succesively optimized versions of
--   the value after each thread recombination, where each version is
--   optimized using parallel multi-threaded optimization.
--   
--   See <a>optoPar</a> for a detailed description on how parallel
--   optimization is implemented.
--   
--   Note that, unlike <a>optoConduit</a>, which is a conduit, this is a
--   conduit (source) <i>transformer</i>. It takes a source outputting
--   <i>samples</i> and returns a <i>new</i> source of <i>optimized
--   values</i>.
--   
--   A value is emitted after every thread recombination/call of
--   <a>poCombine</a>.
optoConduitPar :: forall m v r a. MonadUnliftIO m => RunOpts m a -> ParallelOpts m a -> a -> Opto m v r a -> ConduitT () r m () -> ConduitT () a m ()
optoConduitParChunk :: forall m v r a. MonadUnliftIO m => RunOpts m a -> ParallelOpts m a -> a -> Opto (StateT [r] m) v r a -> ConduitT () r m () -> ConduitT () a m ()

-- | The mean of the values in a non-empty container.
mean :: (Foldable1 t, Fractional a) => t a -> a
instance (GHC.Num.Num a, GHC.Num.Num b) => GHC.Base.Semigroup (Numeric.Opto.Run.Sum2 a b)
instance (GHC.Num.Num a, GHC.Num.Num b) => GHC.Base.Monoid (Numeric.Opto.Run.Sum2 a b)
instance (GHC.Base.Applicative m, GHC.Real.Fractional a) => Data.Default.Class.Default (Numeric.Opto.Run.ParallelOpts m a)
instance GHC.Base.Functor m => Data.Functor.Invariant.Invariant (Numeric.Opto.Run.ParallelOpts m)
instance GHC.Base.Applicative m => Data.Default.Class.Default (Numeric.Opto.Run.RunOpts m a)
instance Data.Functor.Contravariant.Contravariant (Numeric.Opto.Run.RunOpts m)
instance Data.Functor.Invariant.Invariant (Numeric.Opto.Run.RunOpts m)

module Numeric.Opto.Optimizer
steepestDescent :: ScalingInPlace m v c a => c -> Grad m r a -> Opto m v r a
newtype Momentum c
Momentum :: c -> Momentum c
[momentumDecay] :: Momentum c -> c
momentum :: forall m v r a c. (PrimMonad m, ScalingInPlace m v c a) => Momentum c -> c -> Grad m r a -> Opto m v r a
newtype Nesterov c
Nesterov :: c -> Nesterov c
[nesterovDecay] :: Nesterov c -> c
nesterov :: forall m v r a c. (PrimMonad m, ScalingInPlace m v c a) => Nesterov c -> c -> Grad m r a -> Opto m v r a
data Adam c
Adam :: !c -> !c -> !c -> !c -> Adam c
[adamStep] :: Adam c -> !c
[adamDecay1] :: Adam c -> !c
[adamDecay2] :: Adam c -> !c
[adamEpsilon] :: Adam c -> !c
adam :: forall m v r a c. (RealFloat c, Floating a, ScalingInPlace m v c a, PrimMonad m) => Adam c -> Grad m r a -> Opto m v r a
data AdaMax c
AdaMax :: !c -> !c -> !c -> !c -> AdaMax c
[adaMaxStep] :: AdaMax c -> !c
[adaMaxDecay1] :: AdaMax c -> !c
[adaMaxDecay2] :: AdaMax c -> !c
[adaMaxEpsilon] :: AdaMax c -> !c
adaMax :: forall m v r a c. (RealFloat c, Metric c a, ScalingInPlace m v c a, PrimMonad m) => AdaMax c -> Grad m r a -> Opto m v r a
instance GHC.Classes.Eq c => GHC.Classes.Eq (Numeric.Opto.Optimizer.AdaMax c)
instance GHC.Show.Show c => GHC.Show.Show (Numeric.Opto.Optimizer.AdaMax c)
instance GHC.Classes.Eq c => GHC.Classes.Eq (Numeric.Opto.Optimizer.Adam c)
instance GHC.Show.Show c => GHC.Show.Show (Numeric.Opto.Optimizer.Adam c)
instance GHC.Classes.Eq c => GHC.Classes.Eq (Numeric.Opto.Optimizer.Nesterov c)
instance GHC.Show.Show c => GHC.Show.Show (Numeric.Opto.Optimizer.Nesterov c)
instance GHC.Classes.Eq c => GHC.Classes.Eq (Numeric.Opto.Optimizer.Momentum c)
instance GHC.Show.Show c => GHC.Show.Show (Numeric.Opto.Optimizer.Momentum c)
instance GHC.Real.Fractional c => Data.Default.Class.Default (Numeric.Opto.Optimizer.AdaMax c)
instance GHC.Real.Fractional c => Data.Default.Class.Default (Numeric.Opto.Optimizer.Adam c)
instance GHC.Real.Fractional c => Data.Default.Class.Default (Numeric.Opto.Optimizer.Nesterov c)
instance GHC.Real.Fractional c => Data.Default.Class.Default (Numeric.Opto.Optimizer.Momentum c)


-- | Generate gradients usable with <a>Numeric.Opto</a> using the
--   <i>backprop</i> library.
module Numeric.Opto.Backprop

-- | Turn a simple <tt>a -&gt; b</tt> function into a <tt><a>Grad</a> m
--   a</tt>.
bpGrad :: (Monad m, Backprop a, Backprop b) => (forall s. Reifies s W => BVar s a -> BVar s b) -> Grad m r a

-- | Turn a <tt>a -&gt; b</tt> function parameterized on <tt>r</tt> into a
--   <tt><a>Grad</a> m a</tt>.
bpGradSample :: (Backprop a, Backprop b, Applicative m) => (forall s. Reifies s W => r -> BVar s a -> BVar s b) -> Grad m r a

module Numeric.Opto

-- | Abstraction over types of mutable references for values. A
--   <tt><a>Ref</a> m a v</tt> means that a <tt>v</tt> is a mutable
--   reference to an <tt>a</tt>, and we may update<i>write</i>modify
--   <tt>v</tt> in context <tt>m</tt>.
--   
--   This allows us to reat mutable vectors and in-place mutable numbers or
--   records in the same way.
class Monad m => Ref m a v | v -> a

-- | Initialize a mutable reference with a given value
thawRef :: Ref m a v => a -> m v

-- | Read an immutable value back from a mutable reference
freezeRef :: Ref m a v => v -> m a

-- | Copy an immutable value into a mutable reference
copyRef :: Ref m a v => v -> a -> m ()

-- | Apply a pure function on an immutable value onto a value stored in a
--   mutable reference.
modifyRef :: Ref m a v => v -> (a -> a) -> m ()

-- | <a>modifyRef</a>, but forces the result before storing it back in the
--   reference.
modifyRef' :: Ref m a v => v -> (a -> a) -> m ()

-- | Apply a pure function on an immutable value onto a value stored in a
--   mutable reference, returning a result value from that function.
updateRef :: Ref m a v => v -> (a -> (a, b)) -> m b

-- | <a>updateRef</a>, but forces the updated value before storing it back
--   in the reference.
updateRef' :: Ref m a v => v -> (a -> (a, b)) -> m b
